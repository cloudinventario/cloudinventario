#!/usr/bin/env python3
import concurrent.futures
import multiprocessing
import os, sys, argparse, logging, yaml, asyncio, setproctitle, time, traceback, re, psutil, json
from pprint import pprint
from prometheus_client import Counter, Gauge, CollectorRegistry, pushadd_to_gateway

# SENTRY
import sentry_sdk
from sentry_sdk.integrations.logging import LoggingIntegration
from sentry_sdk.integrations.excepthook import ExcepthookIntegration

# XXX: this is for setproctitle
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning) 

DN = os.path.dirname(os.path.abspath(__file__))

sys.path.append(DN + '/src')
from cloudinventario.cloudinventario import CloudInventario
import cloudinventario.storage as storage

# getArgs
def getArgs():
   parser = argparse.ArgumentParser(description='CloudInventory args')
   parser.add_argument('-c', '--config', action='store', required=False,
                       help='Config file')
   parser.add_argument('-jc', '--json-config', action='store', required=False,
                       help='JSON Config string')
   parser.add_argument('-l', '--list', action='store_true',
                       help='List collectors')
   parser.add_argument('-n', '--name', action='store',
                       help='Collector to run')
   parser.add_argument('-a', '--all', action='store_true',
                       help='Run all collectors')
   parser.add_argument('-p', '--prune', action='store_true',
                       help='Cleanup old data')
   parser.add_argument('-f', '--forks', action='store', nargs='?', type=int,
                       help='Parallel collectors')
   parser.add_argument('-t', '--tasks', action='store', nargs='?', type=int,
                       help='Parallel tasks per collector')
   parser.add_argument('-v', '--verbose', action='count', default=0,
                       help='Verbose')
   parser.add_argument('--test-login', action='store_true', default=0,
                       help='Testing if configuration is correct')
   parser.add_argument('--check-permission', action='store_true', default=0,
                       help='If credentials do not have permission for resource, resource will be skipped')
   args = parser.parse_args()
   if not (args.config or args.json_config):
     parser.error(message='No config was provided. Require Config file or JSON Config string')
   return args

# loadConfig
def loadConfig(config_file):
    with open(config_file) as file:
        return yaml.safe_load(file)
    return None

# loadJSONConfig
def loadJSONConfig(config_text):
    return json.loads(config_text)

# loadPrometheus
def loadPrometheus(config):

    registry = CollectorRegistry()
    metrics = dict()
    # Counter
    metrics['cloudinventario_entries_collected'] = Counter(
        'cloudinventario_entries_collected',
        '',
        ['source'],
        registry=registry,
    )
    metrics['cloudinventario_runtime'] = Gauge(
        'cloudinventario_runtime',
        '',
        ['source'],
        registry=registry,
    )
    metrics['cloudinventario_source'] = Counter(
        'cloudinventario_source',
        '',
        registry=registry,
    )
    metrics['cloudinventario_up'] = Counter(
        'cloudinventario_up',
        '',
        registry=registry,
    )

    # Gauge
    metrics['cloudinventario_success'] = Gauge(
        'cloudinventario_success',
        '',
        ['source'],
        registry=registry,
    )
    metrics['cloudinventario_error'] = Gauge(
        'cloudinventario_error',
        '',
        ['source', 'stage'],
        registry=registry,
    )
    metrics['cloudinventario_cpu_usage'] = Gauge(
        'cloudinventario_cpu_usage',
        '',
        ['source'],
        registry=registry,
    )
    metrics['cloudinventario_mem_usage'] = Gauge(
        'cloudinventario_mem_usage',
        '',
        ['source'],
        registry=registry,
    )

    # options defaults
    options = {
      'prometheus_enabled': False,
    }

    # noop pushadd
    pushadd = lambda: None

    prometheus_gateway = os.getenv("PROMETHEUS_GATEWAY")
    if not prometheus_gateway and 'prometheus' in config and isinstance(config['prometheus'], dict):
      prometheus_gateway = config['prometheus'].get('gateway')

    if prometheus_gateway:
      prometheus_job = (os.getenv("PROMETHEUS_JOB") or config['prometheus'].get('job', 'Cloudinventario'))
      logging.info("PrometheusConfig with gateway={}, job={}".format(prometheus_gateway, prometheus_job))

      pushadd = lambda: pushadd_to_gateway(
           prometheus_gateway, 
           prometheus_job,
           registry,
        )

      options = {**options, **{
        'prometheus_enabled': True,
        'prometheus_metrics': metrics,
        'prometheus_registry': registry,
        'prometheus_pushadd': pushadd,
      }}
      return metrics, pushadd, options

    return metrics, pushadd, options

def get_resource(runtime_start, proc):
  runtime = time.time() - runtime_start
  cpu_usage = proc.cpu_percent()
  mem_usage = psutil.virtual_memory()[2]
  return runtime, cpu_usage, mem_usage

# collect
def collect(data):
   config = data['config']
   name = data['name']
   options = data['options']

   proctitle = setproctitle.getproctitle()
   setproctitle.setproctitle("[cloudinventario] {}".format(name))
   multiprocessing.current_process().name = name

   cinv = CloudInventario(config)

   logging.info("collector name={}".format(name))
   runtime_start = time.time()
   try:
     # Check if testing login
     if args.test_login:
        return cinv.login(name, options)

     proc = psutil.Process()
     proc.cpu_percent(0.1)
     runtime_start = time.time()

     inventory = cinv.collect(name, options)
     runtime, cpu_usage, mem_usage = get_resource(runtime_start, proc)

     if inventory is not None:
        logging.info("storing data for name={}".format(name))
        cinv.store(inventory, runtime)
        logging.debug("collector name={} finished".format(name))
        return True, {'name': name, 'runtime': runtime, 'cpu_usage': cpu_usage, 'mem_usage': mem_usage}
     else:
        cinv.store_status(name, storage.STATUS_FAIL, runtime)
        logging.info("collector failed name={}".format(name))
   except Exception as e:
     runtime, cpu_usage, mem_usage = get_resource(runtime_start, proc)
     trace = traceback.format_exc()
     tb = str(traceback.format_exc()).split('\n')
     for  index, line in enumerate(tb):
        if 'in collect' in line:
          stage = re.search(r'([a-z]*?)\.(.*)\(', tb[index+1])
          stage = stage.group(2) if stage else None 
          break

     cinv.store_status(name, storage.STATUS_ERROR, runtime, trace)
     logging.error("collector name={} failed with exception".format(name), exc_info=e)
     return False, {'name': name, 'runtime': runtime, 'cpu_usage': cpu_usage, 'mem_usage': mem_usage, 'stage': stage}
   finally:
     setproctitle.setproctitle(proctitle)
   return False, {'name': name, 'runtime': runtime, 'cpu_usage': cpu_usage, 'mem_usage': mem_usage, 'stage': 'end'}

# sentry load and apply config
def sentryConfig(config, level):
  dsn = os.getenv("SENTRY_DSN")
  if not dsn and 'sentry' in config and isinstance(config['sentry'], dict):
    dsn = config['sentry'].get('dsn')

  if not dsn:
    return False

  environment= (os.getenv("SENTRY_ENVIRONMENT") or config.get('sentry').get('env', 'dev'))
  traces_sample_rate= float(os.getenv("SENTRY_TSR") or config.get('sentry').get('tsr', '1.0'))
  event_level= int(os.getenv("SENTRY_EVENT_LEVEL") or config.get('sentry').get('event_level', logging.ERROR))
  
  logging.info("SentryConfig with dsn={}, env={}, traces_sample_rate={}, event_lvl={}".format(dsn, environment, traces_sample_rate, event_level))
  sentry_sdk.init(
    dsn=dsn, 
    integrations=[
        LoggingIntegration(
            level=level,
            event_level=event_level
        ),
        ExcepthookIntegration(always_run=True)
    ],
    environment=environment, 
    traces_sample_rate=traces_sample_rate, 
  )
  return True

# main
def main(args):

  # init logging
  level = logging.WARNING
  if args.verbose > 1:
    level = logging.DEBUG
  elif args.verbose > 0:
    level = logging.INFO
  logging.basicConfig(format='%(asctime)s [%(processName)s] [%(levelname)s] %(message)s', level=level)

  # parse config
  if args.config:
    config = loadConfig(args.config)
  else:
    print(f"[+] Config |{args.json_config}|")
    config = loadJSONConfig(args.json_config)
  cinv = CloudInventario(config)
  sentryConfig(config, level)

  # load prometheus (create registry, define metrics, load gateway and job name)
  METRICS, PROMETHEUS_PUSHADD, prometheus_options  = loadPrometheus(config)

  options = {
    "tasks": args.tasks or 2,
    "check_permission": True if args.check_permission else False,
  }

  if args.prune:
    cinv.cleanup(days = 5)

  if args.list:
    for col in cinv.collectors:
      print("{}".format(col))
    return 0
  elif args.name:
    # Check if testing login
    if args.test_login:
      return cinv.login(args.name, options)
    else:
      options = {**options, **prometheus_options}

      inventory = cinv.collect(args.name, options) 
      cinv.store(inventory)

      METRICS['cloudinventario_up'].inc()
      PROMETHEUS_PUSHADD()
      return 0
  elif args.all:
    # force DB setup
    cinv.store(None)

    for collector in cinv.collectors:
     METRICS['cloudinventario_source'].inc()
     METRICS['cloudinventario_entries_collected'].labels(source=collector).inc()

    # execute concurently
    ret = 1
    with concurrent.futures.ProcessPoolExecutor(max_workers = args.forks or 7) as executor:
      data = []
      for col in cinv.collectors:
        data.append({
           "config": config,
           "name": col,
           "options": options
         })

      # if at least one succeeded, its SUCCESS
      for res in executor.map(collect, data):
        METRICS['cloudinventario_cpu_usage'].labels(source=res[1]['name']).set(res[1]['cpu_usage'])
        METRICS['cloudinventario_mem_usage'].labels(source=res[1]['name']).set(res[1]['mem_usage'])
        METRICS['cloudinventario_runtime'].labels(source=res[1]['name']).set(res[1]['runtime'])
        if res[0] is True:
          METRICS['cloudinventario_success'].labels(source=res[1]['name']).inc()
          ret = 0
        else:
          METRICS['cloudinventario_error'].labels(source=res[1]['name'], stage=res[1]['stage']).inc()
    METRICS['cloudinventario_up'].inc() if ret == 0 else None
    PROMETHEUS_PUSHADD()
    return ret
  elif args.prune:
    return 0
  else:
    print("No action specified !", file=sys.stderr)
    return 1

# MAIN
args = getArgs()
ret = main(args)
sys.exit(ret)
